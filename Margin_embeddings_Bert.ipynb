{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is an attempt at the implementation of [Margin-based Parallel Corpus Mining with Multilingual Sentence Embeddings](https://aclanthology.org/P19-1309) (Artetxe & Schwenk, ACL 2019), and attempting at utilising it for parallel corpus mining of low ressource languages (in our case, we are working with North African Dialects)."
      ],
      "metadata": {
        "id": "wv9GRFZxHpM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "h_tNZkY8H6Dn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRIrXhb8KQbH"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=BertTokeninzer.from_pretrained('UBC-NLP/MARBERT')"
      ],
      "metadata": {
        "id": "syKD9tTjIYB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j06vcorRLz9L",
        "outputId": "f194f761-226c-4ef5-a6a6-891ca9bea876"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing BertModel.\n",
            "\n",
            "All the weights of BertModel were initialized from the TF 2.0 model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "MARBERT=BertModel.from_pretrained('/content/drive/MyDrive/Marbert_tuned')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrzrh2KJRdFP"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/corp.mor', 'r') as f:\n",
        "    mor_sentences = [line.strip() for line in f]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhajkhGSRvVc"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/corp.alg', 'r') as f:\n",
        "    alg_sentences = [line.strip() for line in f]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "fnCrNc3T9ZWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "3GVqB-4z9YIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AEnFd8AL9cP0",
        "outputId": "82ebf6c0-a1df-46a2-8912-fec07d1cd47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Pre-Processing"
      ],
      "metadata": {
        "id": "QzmJonXTIjv7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EYm_uiKR3HV"
      },
      "outputs": [],
      "source": [
        "mor_tokenized=[['[CLS]']+tokenizer.tokenize(sentence)+['[SEP]'] for sentence in mor_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dG0I0CdQSJ8I"
      },
      "outputs": [],
      "source": [
        "alg_tokenized=[['[CLS]']+tokenizer.tokenize(sentence)+['[SEP]'] for sentence in alg_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZW2-9h37TbrL"
      },
      "outputs": [],
      "source": [
        "maxlen=75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNN-v7f_TgzP"
      },
      "outputs": [],
      "source": [
        "padded_mor=[tokens +['[PAD]' for _ in range(maxlen-len(tokens))] for tokens in mor_tokenized]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZIpiggjUI16"
      },
      "outputs": [],
      "source": [
        "padded_alg=[tokens +['[PAD]' for _ in range(maxlen-len(tokens))] for tokens in alg_tokenized]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0L3t_73UKh2"
      },
      "outputs": [],
      "source": [
        "seg_ids_mor=[[0 for _ in range(len(padded))]for padded in padded_mor]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7mFcPJ9Yxdw"
      },
      "outputs": [],
      "source": [
        "seg_ids_alg=[[0 for _ in range(len(padded))]for padded in padded_alg]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0xyJQZkU-20"
      },
      "outputs": [],
      "source": [
        "sent_ids_mor=[tokenizer.convert_tokens_to_ids(padded) for padded in padded_mor]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4bRtxAtU_-9"
      },
      "outputs": [],
      "source": [
        "sent_ids_alg=[tokenizer.convert_tokens_to_ids(padded) for padded in padded_alg]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dd9C_gPbVN3m"
      },
      "outputs": [],
      "source": [
        "attn_mask_mor=[[ 1 if token != '[PAD]' else 0 for token in padded ]for padded in padded_mor]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kxmq_hYUZIdr"
      },
      "outputs": [],
      "source": [
        "attn_mask_alg=[[ 1 if token != '[PAD]' else 0 for token in padded ]for padded in padded_alg]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlOgk6K_g08m"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lryZ77z7ZOQT"
      },
      "outputs": [],
      "source": [
        "token_ids_mor = [torch.tensor(sent_ids).unsqueeze(0).to(device) for sent_ids in sent_ids_mor ]\n",
        "attn_mask_mor = [torch.tensor(attn_mask).unsqueeze(0).to(device) for attn_mask in attn_mask_mor]\n",
        "seg_ids_mor = [torch.tensor(seg_ids).unsqueeze(0).to(device) for seg_ids in seg_ids_mor]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrTVXRFhbJwE"
      },
      "outputs": [],
      "source": [
        "token_ids_alg = [torch.tensor(sent_ids).unsqueeze(0).to(device) for sent_ids in sent_ids_alg]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPEEkMpteLoM"
      },
      "outputs": [],
      "source": [
        "attn_mask_alg = [torch.tensor(attn_mask).unsqueeze(0).to(device) for attn_mask in attn_mask_alg]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THX22-qeeQOg"
      },
      "outputs": [],
      "source": [
        "seg_ids_alg   = [torch.tensor(seg_ids).unsqueeze(0).to(device) for seg_ids in seg_ids_alg]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MARBERT.to(device)"
      ],
      "metadata": {
        "id": "nWm0cq7pultM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We write the [CLS] token embedding into a file as it contains a representation of the whole sentence. We can also use a pooler output of the model (mean-pooled) and look for the encoder layer that gives us the best sentence representation. Not that the model used has already been fine tuned for the classification task."
      ],
      "metadata": {
        "id": "ajmbk9N2I2y6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reason we write the embeddings into a file is because the embeddings have a high dimensionnality and then require more VRAM than what we have at hand."
      ],
      "metadata": {
        "id": "CPeDm2AgJp8y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XddADXlLbpbW"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/algerian_cls_embeddings_1', 'w') as f:\n",
        "  i=0\n",
        "  f.write(f\"id | cls_embedding\\n\")\n",
        "  for token_ids, attn_mask, seg_ids in zip(token_ids_alg, attn_mask_alg, seg_ids_alg):\n",
        "    f.write(f\"{i}  | {MARBERT(token_ids, attention_mask = attn_mask).last_hidden_state[0][0].tolist()} \\n\")\n",
        "    i=i+1 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/moroccan_cls_embeddings_', 'w') as f:\n",
        "  i=0\n",
        "  f.write(f\"id | cls_embedding \\n\")\n",
        "  for token_ids, attn_mask, seg_ids in zip(token_ids_mor, attn_mask_mor, seg_ids_mor):\n",
        "    f.write(f\"{i}  | {MARBERT(token_ids, attention_mask = attn_mask).last_hidden_state[0][0].tolist()} \\n\")\n",
        "    i=i+1 "
      ],
      "metadata": {
        "id": "Oh7_SLpz19bC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "7nzZK3Kc7AZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read\n",
        "If you have the embeddings start from here.\n",
        "\n",
        "Link to Pytorch tuned marbert https://drive.google.com/drive/folders/1-9fNj9RaAErb9VCjgaLxKGT-tkFRF4R4?usp=sharing\n",
        "\n",
        "Link to alg CLS emb: https://drive.google.com/file/d/10EZD1qs9U1vjhwaP-LrPH9eToNvs8w27/view?usp=sharing\n",
        "\n",
        "Link to mor CLS emb:\n",
        "https://drive.google.com/file/d/10DmcHc-l7I_POmDs5FU7OyPsM4QL7eJB/view?usp=sharing"
      ],
      "metadata": {
        "id": "RwwBACBtRF1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_mor= pd.read_csv('/content/drive/MyDrive/moroccan_cls_embeddings_', sep='|', names=['id','cls_emb']).set_index('id')"
      ],
      "metadata": {
        "id": "Kxt7AIQd7DWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_mor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "09-WNDnvIa_N",
        "outputId": "da1d6c94-7f7a-4bdc-d7eb-0ce82a892141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  cls_emb\n",
              "id                                                       \n",
              "id                                         cls_embedding \n",
              "0        [-0.3836098611354828, -0.12836281955242157, 0...\n",
              "1        [-0.4837908148765564, -0.10353101789951324, 0...\n",
              "2        [0.03222808986902237, -0.06129252910614014, 1...\n",
              "3        [-0.026018619537353516, -0.07560951262712479,...\n",
              "...                                                   ...\n",
              "6407     [-0.3569198548793793, -0.14029435813426971, 0...\n",
              "6408     [0.02530290000140667, -0.06131020560860634, -...\n",
              "6409     [0.07313661277294159, -0.07153552770614624, 1...\n",
              "6410     [0.0845789685845375, -0.08402840793132782, 1....\n",
              "6411     [-0.5652677416801453, -0.19824232161045074, 0...\n",
              "\n",
              "[6413 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4339052-8d21-4407-abcc-034d9de35532\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cls_emb</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>cls_embedding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-0.3836098611354828, -0.12836281955242157, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-0.4837908148765564, -0.10353101789951324, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.03222808986902237, -0.06129252910614014, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-0.026018619537353516, -0.07560951262712479,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6407</th>\n",
              "      <td>[-0.3569198548793793, -0.14029435813426971, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6408</th>\n",
              "      <td>[0.02530290000140667, -0.06131020560860634, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6409</th>\n",
              "      <td>[0.07313661277294159, -0.07153552770614624, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6410</th>\n",
              "      <td>[0.0845789685845375, -0.08402840793132782, 1....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6411</th>\n",
              "      <td>[-0.5652677416801453, -0.19824232161045074, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6413 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4339052-8d21-4407-abcc-034d9de35532')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4339052-8d21-4407-abcc-034d9de35532 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4339052-8d21-4407-abcc-034d9de35532');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_alg= pd.read_csv('/content/drive/MyDrive/algerian_cls_embeddings_1', sep='|', names=['id','cls_emb']).set_index('id')"
      ],
      "metadata": {
        "id": "2valh_4I_Iya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cos_sim=torch.nn.CosineSimilarity(dim=1, eps=1e-6)"
      ],
      "metadata": {
        "id": "7yOR1kuC90CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hubness\n",
        "The tendency of high-dimensional data to contain points (hubs) that frequently occur in k-nearest-neighbor lists of other points.\n",
        "As we are using embeddings from our pretrained Bert model (high-dimensional data), we chose to adopt a margin based approach in order to  mine our corpus for parallel sentences."
      ],
      "metadata": {
        "id": "rMDP8Cp-EBNs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Margin based scoring\n",
        "This method has been inspired by *Mikel Artexe* and *Holger Schwenk*'s paper on Margin-based *Parallel Corpus Mining\n",
        "with Multilingual Sentence Embeddings*. \n",
        "\n",
        "We consider the margin between the cosine of a\n",
        "given candidate and the average cosine of its k\n",
        "nearest neighbors in both directions as follows:\n",
        "\n",
        "$$score(x,y)=margin(cos(x,y),\n",
        "\\\\∑_{z \\in NN_k(x)}{\\dfrac{cos(x,z)}{2k}} + ∑_{z \\in NN_k(y)}{\\dfrac{cos(y,z)}{2k}} )$$\n",
        "Where $NNk(x)$ denotes the nearest neighbors of x and the other language excluding duplicates (same thing for $NNk(y)$).\n",
        "As for the margin, it can be either:\n",
        "  * Absolute: $margin(a,b)=a$\n",
        "  * Distance: $margin(a,b)=a-b$\n",
        "  * Ration: $margin(a,b)=a/b$"
      ],
      "metadata": {
        "id": "pRhZ93hGA3nv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Determining NNk based on cosine similarity"
      ],
      "metadata": {
        "id": "_2dj9ltwG10-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nnSimAlg(emb, n):\n",
        "  cos_sim_table=[cos_sim(emb, sentence) for sentence in alg_emb]\n",
        "  a=sorted(range(len(alg_emb)), key=lambda i: cos_sim_table[i], reverse=True)[:n+1]\n",
        "  return a\n",
        "def nnSimMor(emb, n):\n",
        "  cos_sim_table=[cos_sim(emb, sentence) for sentence in mor_emb]\n",
        "  a=sorted(range(len(mor_emb)), key=lambda i: cos_sim_table[i], reverse=True)[:n+1]\n",
        "  return a\n",
        "def Margin_score(mor_embed, alg_embed, n):\n",
        "  mor=nnSimMor(mor_embed, n)\n",
        "  alg=nnSimAlg(alg_embed, n)\n",
        "  sum_cos_mor=0\n",
        "  sum_cos_alg=0\n",
        "  for i in range(n):\n",
        "    sum_cos_mor=sum_cos_mor+(cos_sim(mor_embed,torch.tensor(mor[i+1])))\n",
        "    sum_cos_alg=sum_cos_alg+(cos_sim(alg_embed,torch.tensor(alg[i+1])))\n",
        "  sum_cos_mor=sum_cos_mor/(2*n)\n",
        "  sum_cos_alg=sum_cos_alg/(2*n)\n",
        "  a=cos_sim(mor_embed,alg_embed)\n",
        "  b=(sum_cos_mor+sum_cos_alg)\n",
        "  score_diff=a-b\n",
        "  score_frac=a/b\n",
        "  score_abs=a\n",
        "  return score_diff, score_frac, score_abs"
      ],
      "metadata": {
        "id": "CyyKZ8rQ5K2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Determining NNk based on distance"
      ],
      "metadata": {
        "id": "mrrLMl0AGM-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.linalg as LA"
      ],
      "metadata": {
        "id": "wWoecln0GIEN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nnNormSimilarMor(emb, n):\n",
        "  norm_table=[LA.vector_norm(emb-sentence, ord=17)for sentence in mor_emb]\n",
        "  a=sorted(range(len(mor_emb)), key=lambda i: norm_table[i])[:n+1]\n",
        "  return a"
      ],
      "metadata": {
        "id": "TrxyTOA-Mtt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nnNormSimilarAlg(emb, n):\n",
        "  norm_table=[LA.vector_norm(emb-sentence, ord=17)for sentence in alg_emb]\n",
        "  a=sorted(range(len(alg_emb)), key=lambda i: norm_table[i])[:n+1]\n",
        "  return a"
      ],
      "metadata": {
        "id": "PYaWkZcoPSYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Margin_score_with_norm(mor_embed, alg_embed, n):\n",
        "  mor=nnNormSimilarMor(mor_embed, n)\n",
        "  alg=nnNormSimilarAlg(alg_embed, n)\n",
        "  sum_cos_mor=0\n",
        "  sum_cos_alg=0\n",
        "  for i in range(n):\n",
        "    sum_cos_mor=sum_cos_mor+(cos_sim(mor_embed,torch.tensor(mor[i+1])))\n",
        "    sum_cos_alg=sum_cos_alg+(cos_sim(alg_embed,torch.tensor(alg[i+1])))\n",
        "  sum_cos_mor=sum_cos_mor/(2*n)\n",
        "  sum_cos_alg=sum_cos_alg/(2*n)\n",
        "  a=cos_sim(mor_embed,alg_embed)\n",
        "  b=(sum_cos_mor+sum_cos_alg)\n",
        "  score_diff=a-b\n",
        "  score_frac=a/b\n",
        "  score_abs=a\n",
        "  return score_diff, score_frac, score_abs"
      ],
      "metadata": {
        "id": "6bYkGRwxPgKu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Margin_embeddings_Bert.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}